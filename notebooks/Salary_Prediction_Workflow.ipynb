{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python","version":"3.10"}},"cells":[{"cell_type":"markdown","metadata":{},"source":["# Salary Prediction — End-to-end Notebook\n","\n","This notebook performs:\n","- Data loading & basic cleaning\n","- Exploratory Data Analysis (EDA)\n","- Preprocessing pipeline (imputation, encoding, scaling)\n","- Model training and comparison (Ridge, RandomForest, XGBoost, LightGBM)\n","- Optional hyperparameter tuning for top candidates\n","- Residual analysis, feature importance, and SHAP explanations\n","- Saves the final pipeline to models/best_pipeline.joblib and metadata to models/meta.joblib\n","\n","Notes:\n","- This notebook intentionally *excludes* Streamlit web app code. You asked to keep everything in the notebook for easier demonstration.\n","- If certain packages (xgboost, lightgbm, shap) are missing, either install them in your environment or skip the corresponding cells."]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"markdown","metadata":{},"source":["## 0. Setup & Imports"]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["# If you run this in a fresh environment, uncomment and run the next cell to install missing packages:\n","# !pip install -r requirements.txt\n","\n","import os\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from pprint import pprint\n","\n","# sklearn\n","from sklearn.model_selection import train_test_split, cross_validate, cross_val_predict\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.linear_model import Ridge\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.model_selection import GridSearchCV\n","\n","# optional 3rd party models\n","try:\n","    from xgboost import XGBRegressor\n","except Exception:\n","    XGBRegressor = None\n","try:\n","    from lightgbm import LGBMRegressor\n","except Exception:\n","    LGBMRegressor = None\n","\n","import joblib\n","\n","plt.style.use(\"seaborn\")\n","sns.set_context(\"notebook\")"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Load data\n","Adjust path if your CSV is in another location."]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["DATA_PATH = \"expected_ctc.csv\"\n","if not os.path.exists(DATA_PATH):\n","    raise FileNotFoundError(f\"Dataset not found at {DATA_PATH}. Place expected_ctc.csv in the repo root.\")\n","\n","df = pd.read_csv(DATA_PATH, low_memory=False)\n","print(\"Initial shape:\", df.shape)\n","df.head(3)"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Target detection & basic cleaning\n","The dataset sometimes doesn't have a clear target column name. We'll look for common names and otherwise use the last column."]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["def detect_target_column(df, candidates=None):\n","    if candidates is None:\n","        candidates = [\"Expected_CTC\", \"Expected CTC\", \"Expected_ctc\", \"expected_ctc\", \"CTC\", \"ctc\", \"expected\", \"Expected\"]\n","    for c in candidates:\n","        if c in df.columns:\n","            return c\n","    return df.columns[-1]\n","\n","target_col = detect_target_column(df)\n","print(\"Using target column:\", target_col)\n","\n","# Clean column names\n","df = df.rename(columns=lambda x: x.strip())\n","\n","# Replace purely-empty strings with NaN\n","df = df.replace(r'^\\s*$', np.nan, regex=True)\n","\n","# Make the target numeric and drop rows missing it\n","df[target_col] = pd.to_numeric(df[target_col], errors=\"coerce\")\n","n_before = df.shape[0]\n","df = df.dropna(subset=[target_col]).reset_index(drop=True)\n","n_after = df.shape[0]\n","print(f\"Dropped {n_before - n_after} rows with missing target\")\n","\n","# Quick target stats\n","display(df[target_col].describe().astype(int))\n","\n","# Show skewness (CTC is usually right-skewed)\n","print(\"Target skew:\", df[target_col].skew())"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Exploratory Data Analysis (suggested / interactive)\n","Below are useful EDA snippets. Run selectively to inspect relationships."]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["# Missing values percent per column (top 40)\n","missing_pct = df.isna().mean().sort_values(ascending=False) * 100\n","display(missing_pct.head(40))"]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["# Visualize target distribution and log-target distribution\n","fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n","sns.histplot(df[target_col], ax=axes[0], kde=True)\n","axes[0].set_title(\"Target distribution\")\n","sns.histplot(np.log1p(df[target_col]), ax=axes[1], kde=True, color=\"orange\")\n","axes[1].set_title(\"Log(1+Target) distribution\")\n","plt.show()"]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["# Check numeric features of interest if they exist (Total_Experience, Total_Experience_in_field_applied)\n","for col in [\"Total_Experience\", \"Total_Experience_in_field_applied\"]:\n","    if col in df.columns:\n","        sns.scatterplot(x=col, y=target_col, data=df.sample(2000, random_state=42))\n","        plt.title(f\"{col} vs {target_col}\")\n","        plt.show()"]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["# Inspect top categorical columns for cardinality and some value counts\n","cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n","cat_card = {c: df[c].nunique(dropna=False) for c in cat_cols}\n","sorted(cat_card.items(), key=lambda x: x[1], reverse=True)[:20]\n","\n","# Show value counts for a few high-impact columns (if present)\n","for c in [\"Role\", \"Department\", \"Industry\", \"Education\", \"Designation\"]:\n","    if c in df.columns:\n","        print(\"----\", c, \"----\")\n","        print(df[c].value_counts(dropna=False).head(10))\n","        print()"]},{"cell_type":"markdown","metadata":{},"source":["Consider log-transforming the target during modeling if error metrics improve (we'll try both approaches later)."]},{"cell_type":"markdown","metadata":{},"source":["## 4. Preprocessing pipeline\n","We'll build a ColumnTransformer:\n","- numeric: SimpleImputer(median) + StandardScaler\n","- categorical: SimpleImputer(constant=\"Missing\") + OneHotEncoder(handle_unknown=\"ignore\")\n","We'll choose numeric / categorical features heuristically:\n","  - All numeric dtypes except ID-like columns go to numeric.\n","  - Object/Category go to categorical.\n","  - Treat integer columns with small unique values (<=10) as categorical."]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["def choose_feature_columns(df, target_col):\n","    X = df.drop(columns=[target_col])\n","    numeric_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n","    cat_from_numeric = [c for c in numeric_cols if X[c].nunique() <= 10]\n","    numeric_cols = [c for c in numeric_cols if c not in cat_from_numeric]\n","    categorical_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist() + cat_from_numeric\n","    # remove id-like columns\n","    id_like = [c for c in X.columns if any(k in c.lower() for k in [\"id\", \"idx\", \"applicant\"]) ]\n","    categorical_cols = [c for c in categorical_cols if c not in id_like]\n","    numeric_cols = [c for c in numeric_cols if c not in id_like]\n","    return numeric_cols, categorical_cols\n","\n","numeric_cols, categorical_cols = choose_feature_columns(df, target_col)\n","print(\"Numeric columns (sample):\", numeric_cols[:20])\n","print(\"Categorical columns (sample):\", categorical_cols[:20])\n","\n","# Construct preprocessor\n","numeric_pipeline = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())])\n","categorical_pipeline = Pipeline([(\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Missing\")),\n","                                 (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False))])\n","\n","preprocessor = ColumnTransformer([(\"num\", numeric_pipeline, numeric_cols),\n","                                   (\"cat\", categorical_pipeline, categorical_cols)],\n","                                  remainder=\"drop\")\n","\n","# Quick test: fit_transform small sample to ensure no errors\n","if len(df) > 0:\n","    X_sample = df.drop(columns=[target_col]).iloc[:50]\n","    _ = preprocessor.fit_transform(X_sample)"]},{"cell_type":"markdown","metadata":{},"source":["## 5. Candidate models & cross-validated comparison\n","We'll train pipelines with:\n","- Ridge\n","- RandomForest\n","- XGBoost (if available)\n","- LightGBM (if available)\n","\n","We'll evaluate with 5-fold CV using RMSE, MAE, R2."]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["from sklearn.model_selection import KFold\n","\n","RANDOM_STATE = 42\n","cv = 5\n","kf = KFold(n_splits=cv, shuffle=True, random_state=RANDOM_STATE)\n","\n","candidates = {\n","    \"Ridge\": Ridge(random_state=RANDOM_STATE),\n","    \"RandomForest\": RandomForestRegressor(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1),\n","}\n","if XGBRegressor is not None:\n","    candidates[\"XGBoost\"] = XGBRegressor(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1, verbosity=0)\n","if LGBMRegressor is not None:\n","    candidates[\"LightGBM\"] = LGBMRegressor(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1, verbosity=-1)\n","\n","results = {}\n","for name, model in candidates.items():\n","    print(\"Evaluating:\", name)\n","    pipe = Pipeline([(\"preprocessor\", preprocessor), (\"model\", model)])\n","    scoring = {\"rmse\": \"neg_root_mean_squared_error\", \"mae\": \"neg_mean_absolute_error\", \"r2\": \"r2\"}\n","    res = cross_validate(pipe, df.drop(columns=[target_col]), df[target_col],\n","                         scoring=scoring, cv=kf, n_jobs=-1, return_train_score=False)\n","    rmse = -res[\"test_rmse\"].mean()\n","    mae = -res[\"test_mae\"].mean()\n","    r2 = res[\"test_r2\"].mean()\n","    results[name] = {\"rmse\": rmse, \"mae\": mae, \"r2\": r2}\n","    print(f\"{name} -> RMSE: {rmse:.2f}, MAE: {mae:.2f}, R2: {r2:.4f}\")\n","    print(\"-\" * 40)\n","\n","# Summarize results as DataFrame\n","res_df = pd.DataFrame(results).T.sort_values(\"rmse\")\n","res_df"]},{"cell_type":"markdown","metadata":{},"source":["If Ridge performs very well compared to tree models, that suggests linear relationships (or good features). If tree models win, we can tune them further."]},{"cell_type":"markdown","metadata":{},"source":["## 6. (Optional) Try training on log-target and compare\n","Because target distribution is likely skewed, training on log(1+target) often reduces RMSE. We'll compare best candidate on original target vs log-target."]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["from sklearn.base import clone\n","\n","def cv_score_pipeline(pipeline, X, y, cv):\n","    scoring = {\"rmse\": \"neg_root_mean_squared_error\", \"mae\": \"neg_mean_absolute_error\"}\n","    res = cross_validate(pipeline, X, y, scoring=scoring, cv=cv, n_jobs=-1)\n","    return {\"rmse\": -res[\"test_rmse\"].mean(), \"mae\": -res[\"test_mae\"].mean()}\n","\n","# choose top candidate from earlier results\n","best_name = res_df.index[0]\n","print(\"Best candidate (original target CV):\", best_name)\n","best_model = candidates[best_name]\n","\n","# Evaluate best_model with log-target\n","pipe_orig = Pipeline([(\"preprocessor\", preprocessor), (\"model\", clone(best_model))])\n","pipe_log = Pipeline([(\"preprocessor\", preprocessor), (\"model\", clone(best_model))])\n","\n","y_log = np.log1p(df[target_col])\n","\n","print(\"CV on original target:\")\n","print(cv_score_pipeline(pipe_orig, df.drop(columns=[target_col]), df[target_col], kf))\n","print(\"CV on log-target (scores are on log-target):\")\n","print(cv_score_pipeline(pipe_log, df.drop(columns=[target_col]), y_log, kf))"]},{"cell_type":"markdown","metadata":{},"source":["## 7. Fit best pipeline on full data & save artifacts\n","We'll pick the method we prefer:\n","- If log-target approach looked better, train on log-target and save an adapter that applies expm1.\n","For demonstration we'll:\n","- Use best candidate from earlier (best_name)\n","- Train on full data (original target)\n","- Save pipeline to models/best_pipeline.joblib and metadata (residual std, mean) to models/meta.joblib"]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["os.makedirs(\"models\", exist_ok=True)\n","\n","final_model = clone(candidates[best_name])\n","final_pipe = Pipeline([(\"preprocessor\", preprocessor), (\"model\", final_model)])\n","\n","print(\"Fitting final pipeline on all data...\")\n","final_pipe.fit(df.drop(columns=[target_col]), df[target_col])\n","\n","# Save pipeline\n","joblib.dump(final_pipe, \"models/best_pipeline.joblib\")\n","# Save preprocessor separately too (useful)\n","joblib.dump(preprocessor, \"models/preprocessor.joblib\")\n","\n","# Compute cross-val predictions to estimate residual distribution\n","print(\"Computing CV predictions to estimate residual distribution...\")\n","cv_preds = cross_val_predict(final_pipe, df.drop(columns=[target_col]), df[target_col], cv=kf, n_jobs=-1)\n","residuals = df[target_col] - cv_preds\n","meta = {\"resid_mean\": float(residuals.mean()), \"resid_std\": float(residuals.std()), \"cv_rmse\": float(mean_squared_error(df[target_col], cv_preds, squared=False))}\n","joblib.dump(meta, \"models/meta.joblib\")\n","\n","print(\"Saved model pipeline and metadata to models/\")\n","\n","# Quick sanity: predict on first 5 rows\n","sample_preds = final_pipe.predict(df.drop(columns=[target_col]).iloc[:5])\n","print(\"Sample predictions:\", sample_preds)"]},{"cell_type":"markdown","metadata":{},"source":["## 8. Residual analysis & simple uncertainty estimate\n","Use the residual standard deviation to give a simple approximate prediction interval (not a calibrated Bayesian interval)."]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["preds_all = final_pipe.predict(df.drop(columns=[target_col]))\n","rmse_full = mean_squared_error(df[target_col], preds_all, squared=False)\n","mae_full = mean_absolute_error(df[target_col], preds_all)\n","r2_full = r2_score(df[target_col], preds_all)\n","print(f\"Training-fit metrics -> RMSE: {rmse_full:.0f}, MAE: {mae_full:.0f}, R2: {r2_full:.4f}\")\n","plt.figure(figsize=(8,4))\n","sns.histplot(df[target_col] - preds_all, bins=60, kde=True)\n","plt.title(\"Residual distribution (train-fit)\")\n","plt.show()\n","\n","# 95% approximate interval on predictions for a candidate:\n","resid_std = meta[\"resid_std\"]\n","print(\"Approx residual std (from CV):\", resid_std)\n","print(\"Approx 95% PI width ±1.96*std:\", 1.96 * resid_std)"]},{"cell_type":"markdown","metadata":{},"source":["## 9. Feature importance & interpretability\n","- If best model is tree-based, show feature importances.\n","- If it's linear (Ridge), show coefficients for numeric features and aggregated importance for OHE features."]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["def get_feature_names_from_preprocessor(prep, numeric_cols, categorical_cols):\n","    \"\"\"Return expanded feature names produced by preprocessor\"\"\"\n","    names = []\n","    # numeric first\n","    names.extend(numeric_cols)\n","    # categorical: get categories_ from onehot encoder\n","    try:\n","        # access the onehot encoder inside the column transformer\n","        for name, transformer, cols in prep.transformers:\n","            if name == \"cat\":\n","                ohe = transformer.named_steps[\"onehot\"]\n","                cat_cols = list(cols)\n","                categories = ohe.categories_\n","                for col, cats in zip(cat_cols, categories):\n","                    names.extend([f\"{col}__{c}\" for c in cats])\n","    except Exception:\n","        # fallback: use categorical column names only\n","        names.extend(categorical_cols)\n","    return names\n","\n","feature_names = get_feature_names_from_preprocessor(preprocessor, numeric_cols, categorical_cols)\n","print(\"Total expanded features (sample):\", len(feature_names))\n","feature_names[:40]"]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["# Feature importance for tree models\n","if best_name in [\"RandomForest\", \"XGBoost\", \"LightGBM\"]:\n","    model = final_pipe.named_steps[\"model\"]\n","    try:\n","        importances = model.feature_importances_\n","        fi = pd.Series(importances, index=feature_names).sort_values(ascending=False).head(40)\n","        plt.figure(figsize=(8, 10))\n","        sns.barplot(x=fi.values[:30], y=fi.index[:30])\n","        plt.title(f\"{best_name} feature importances (top 30)\")\n","        plt.show()\n","    except Exception as e:\n","        print(\"Could not compute feature importances:\", e)\n","\n","# Coefficients for Ridge\n","if best_name == \"Ridge\":\n","    coef = final_pipe.named_steps[\"model\"].coef_\n","    coefs = pd.Series(coef, index=feature_names).sort_values(key=abs, ascending=False).head(40)\n","    plt.figure(figsize=(8,10))\n","    sns.barplot(x=coefs.values, y=coefs.index)\n","    plt.title(\"Ridge: top coefficient magnitudes\")\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## 10. SHAP explanations (optional & recommended)\n","Compute SHAP summary for a sample if the model supports TreeExplainer (tree models) or KernelExplainer (slower).\n","Install shap if missing: pip install shap"]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["try:\n","    import shap\n","    shap_available = True\n","except Exception:\n","    shap_available = False\n","    print(\"shap not installed — skip SHAP cells or install shap to enable them.\")\n","\n","if shap_available:\n","    # use a sample (to speed up)\n","    X_full = df.drop(columns=[target_col])\n","    X_sample = X_full.sample(n=min(500, len(X_full)), random_state=RANDOM_STATE)\n","    # convert using preprocessor and then use model-specific explainer\n","    # For convenience, use the pipeline's preprocessor to get numpy array\n","    X_trans = preprocessor.transform(X_sample)\n","    model = final_pipe.named_steps[\"model\"]\n","    explainer = None\n","    if best_name in [\"RandomForest\", \"XGBoost\", \"LightGBM\"]:\n","        try:\n","            explainer = shap.TreeExplainer(model)\n","            shap_values = explainer.shap_values(X_trans)\n","            # Use feature names already expanded\n","            shap.summary_plot(shap_values, X_trans, feature_names=feature_names, show=True)\n","        except Exception as e:\n","            print(\"TreeExplainer failed:\", e)\n","            explainer = None\n","    if explainer is None:\n","        try:\n","            # KernelExplainer with a background sample (slow)\n","            background = X_trans[np.random.choice(X_trans.shape[0], size=min(100, X_trans.shape[0]), replace=False)]\n","            explainer = shap.KernelExplainer(model.predict, background)\n","            shap_values = explainer.shap_values(X_trans[:50])\n","            shap.summary_plot(shap_values, X_trans[:50], feature_names=feature_names)\n","        except Exception as e:\n","            print(\"KernelExplainer failed:\", e)\n"]},{"cell_type":"markdown","metadata":{},"source":["## 11. Save a small evaluation report\n","Save CV results table and metadata so you can attach in demo."]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["report = {\"cv_results\": results, \"cv_summary\": res_df.to_dict(), \"best_model\": best_name, \"meta\": meta}\n","joblib.dump(report, \"models/report.joblib\")\n","print(\"Saved models/report.joblib\")\n","\n","# Also save a CSV summary of the comparison\n","res_df.to_csv(\"models/model_comparison.csv\")\n","print(\"Saved models/model_comparison.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## 12. How to use the saved pipeline to predict new candidates\n","Demonstration code snippet that you can copy into a script or notebook when using saved model."]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["# Example:\n","loaded = joblib.load(\"models/best_pipeline.joblib\")\n","example_row = df.drop(columns=[target_col]).iloc[0:1]\n","print(\"Example input row (first row):\")\n","display(example_row.T.head(30))\n","pred_example = loaded.predict(example_row)[0]\n","print(\"Predicted Expected CTC for example row:\", pred_example)\n","\n","# If you used log-target training, call np.expm1 on the prediction to invert."]},{"cell_type":"markdown","metadata":{},"source":["## 13. Next steps & tips (for your presentation)\n","- Inspect `models/model_comparison.csv` and `models/report.joblib` during your demo.\n","- If you want to show fairness checks:\n","  - Group by Department/Role/Education and compare median predicted vs actual for similarly-qualified groups.\n","  - Compute parity metrics (e.g., mean absolute difference between groups).\n","- For reproducibility on other machines, provide `requirements.txt` and the `models/` artifacts.\n","- If you'd like I can also:\n","  - add a cell to generate a small HTML report (pdf) summarizing EDA and evaluation,\n","  - or produce a condensed Jupyter slideshow (RISE) friendly presentation of the notebook.\n","\n","This notebook runs the full modeling workflow and stores artifacts in the `models/` directory."]}]}